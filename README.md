# ğŸŒ CoughChain: An Environmentally Adaptive Cough Detection Framework Guided by Diverse Chain-of-Thought Prompting in LLM

CoughChain is a **training-free**, large language model (LLM)-based cough detection framework that leverages **diverse chain-of-thought (CoT) prompting strategies** and **environment-aware context injection** to achieve robust and interpretable cough recognition in complex acoustic environments.

> ğŸ” **Core Idea**: By explicitly informing the LLM whether the input audio comes from a *"quiet"* or *"noisy"* environmentâ€”and guiding its reasoning through structured CoT promptsâ€”the model **adaptively adjusts its decision logic** without any fine-tuning or parameter updates.

---

## ğŸ“Œ Key Highlights

- âœ… **Zero training required**: Uses off-the-shelf LLM (Qwen-Omni-Turbo) via prompt engineering only  
- ğŸ§  **Four CoT reasoning strategies**:
  - `audiofeature`: Audio featureâ€“guided reasoning (e.g., spectral, energy, zero-crossing rate)
  - `step`: Linear, step-by-step logical decomposition
  - `selfask`: Iterative self-questioning and answering to refine judgment
  - `tot` (Tree of Thought): Multi-branch tree-like reasoning with path exploration and consensus
- ğŸŒ **Environment-adaptive**: Dynamically switches reasoning strategy based on acoustic context ("quiet" vs. "noisy")
- ğŸ¯ Evaluated on a **balanced, real-world multi-scenario cough dataset**

---

## ğŸ“‚ Code Structure

The repository contains three main directories, each corresponding to a specific experimental setting:

| Directory / File | Description |
|------------------|-------------|
| `cot/`           | **Baseline & four CoT implementations** using **Qwen-Omni-Turbo**:<br>â€¢ `audiofeature.py` â€“ LLM reasoning guided by audio features<br>â€¢ `step.py` â€“ Stepwise logical decomposition of cough judgment<br>â€¢ `selfask.py` â€“ Self-questioning to iteratively focus on key evidence<br>â€¢ `tot.py` â€“ Tree-based multi-path reasoning with final consensus |
| `quiet/`         | **Quiet-environment evaluation**: Runs CoughChain with `"quiet"` context injected into prompts |
| `noisy/`         | **Noisy-environment evaluation**: Runs CoughChain with `"noisy"` context to enhance robustness against interference |

> ğŸ’¡ All implementations are **purely prompt-driven**â€”switching environments or reasoning styles only requires modifying the prompt template. **No model weights are altered.**

---

## âš™ï¸ Essential Setup Before Running

Before executing any script, complete the following two critical configurations:

### 1. Configure Your Qwen API Key
Obtain your **Qwen-Omni-Turbo API key** from the [DashScope Console](https://dashscope.console.aliyun.com/), then choose one of the following methods:

- **Option A: Hardcode in script (for quick testing)**
  ```python
  client = OpenAI(
      api_key="YOUR_API_KEY_HERE",  # â† Replace with your actual key
      base_url="https://dashscope.aliyuncs.com/..."
  )

### 2. Update the Audio Root Directory Path (â—Critical!)
In every Python script (e.g., cot/audiofeature.py, noisy/selfask.py, etc.), locate the following line:
  ```python
  root_audio_dir = "/path/to/your/cough_audio_dataset"  # â† MUST UPDATE!Replace it with the absolute or relative path to your local cough audio folder.
  ```

## ğŸ“Š Code and Data Availability

- ğŸ”’ The **full source code** will be publicly released upon **official acceptance of the paper**.
- ğŸ“ A **subset of the cough audio dataset** will be provided in this repository .
- ğŸ“© For access to the **complete dataset** (including noisy-scenario recordings and metadata), please contact us via email at: **fmingkk@163.com**.

> We encourage the use of this data strictly for academic and non-commercial research purposes, in accordance with ethical guidelines.
